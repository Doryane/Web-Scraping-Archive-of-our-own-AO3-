{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPmR+YD9eAiOP1kJhEMoA1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doryane/Web-Scrapping-Archive-of-our-own-AO3-/blob/main/Web_Scrapping_AO3_part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# What this code do ?\n",
        "\n",
        "In this last part, after the download of all the database you need, you can \"mash up\" everything.\n",
        "It's not really hard to do to be honest but at least you have a code already made."
      ],
      "metadata": {
        "id": "umVIH3Ola7TO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**So to refresh what we've done -**\n",
        "\n",
        "In part 1 (or part 2) we append a certain number of data from one page (Beginning_Page) to another page (Number_page) from AO3.\n",
        "\n",
        "Last code can't append every page from a tag/fandom in one time expect if your tag/fandom have less than 1000 works.\n",
        "\n",
        "What you can do is use part 1 (or part 2) to append every 50 (or other random SAME intervale lenght of page) page of work.\n",
        "\n",
        "That's what I did.\n",
        "\n",
        "For example, if your tag/fandom have 3126 page (like Stranger Things on 25/01/2022) you wan create a first database for page 3000 to 3050, then 3050 to 3100 etc ... to page 1 to 50 and then mash every dataframe.\n",
        "\n",
        "When I say mash I mean combine but mash is more fun to say.\n",
        "\n",
        "That's what we doing today."
      ],
      "metadata": {
        "id": "pK_BlG6qbQ3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "JDxmTpImarqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25768916-e51e-487a-bac4-8154044bfc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'sample_data': Is a directory\n"
          ]
        }
      ],
      "source": [
        "# ! rm *\n",
        "# Use it if you need to clean the data from your workplace"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Library**"
      ],
      "metadata": {
        "id": "6CefQBSRdi54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "from pandas.io.formats.style_render import DataFrame"
      ],
      "metadata": {
        "id": "2WULY0x-domo"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameters**"
      ],
      "metadata": {
        "id": "96ggmwm9eK6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I'm just gonna ask you the beginning page and ending page of all your databases.\n",
        "\n",
        "For example if you appended some fandom from page 26 to page 135 put Beginning_Page = 26 and Number_page = 135.\n",
        "\n",
        "I need also the interval between the page, it ***MUST*** be regular like every 20 pages, every 50 pages etc..\n",
        "\n",
        "Also I need you to uploaded every base you append."
      ],
      "metadata": {
        "id": "SQpaT0nleOS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Debut page\n",
        "Beginning_Page = 26"
      ],
      "metadata": {
        "id": "jMdrEJz_fF9a"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ending Page\n",
        "Number_page = 127\n",
        "Number_page = Number_page - 1"
      ],
      "metadata": {
        "id": "340iWbK_fHWM"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Interval_page = 20"
      ],
      "metadata": {
        "id": "LxeB4YvDfUnH"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "# Saving base_page_126_to_135.csv to base_page_126_to_135.csv\n",
        "# Saving base_page_106_to_127.csv to base_page_106_to_127.csv\n",
        "# Saving base_page_86_to_107.csv to base_page_86_to_107.csv\n",
        "# Saving base_page_66_to_87.csv to base_page_66_to_87.csv\n",
        "# Saving base_page_46_to_67.csv to base_page_46_to_67.csv\n",
        "# Saving base_page_26_to_47.csv to base_page_26_to_47.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "cQ128NrBiqb8",
        "outputId": "24c07cbe-1ed4-43a6-b593-e806d46256a8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8bd4d78a-dc3b-4938-85a8-2fbc714f1d95\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8bd4d78a-dc3b-4938-85a8-2fbc714f1d95\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving base_page_126_to_135.csv to base_page_126_to_135.csv\n",
            "Saving base_page_106_to_127.csv to base_page_106_to_127.csv\n",
            "Saving base_page_86_to_107.csv to base_page_86_to_107.csv\n",
            "Saving base_page_66_to_87.csv to base_page_66_to_87.csv\n",
            "Saving base_page_46_to_67.csv to base_page_46_to_67.csv\n",
            "Saving base_page_26_to_47.csv to base_page_26_to_47.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funny thing to do before running the code"
      ],
      "metadata": {
        "id": "_e1wODGHmL24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inter_one = [Beginning_Page]\n",
        "inter_two = [Beginning_Page + Interval_page + 1]\n",
        "move_for_inter_one_2 = []\n",
        "move_for_inter_two_2 = []\n",
        "Number_inter = (Number_page - 1)/Interval_page - Beginning_Page/Interval_page\n",
        "for i in range(round(Number_inter)):\n",
        "  move_for_inter_one = 0\n",
        "  move_for_inter_one = i*Interval_page + Interval_page\n",
        "\n",
        "  move_for_inter_two = i*Interval_page + Interval_page\n",
        "\n",
        "  move_for_inter_one_2.append(move_for_inter_one)\n",
        "  move_for_inter_two_2.append(move_for_inter_two)\n",
        "\n",
        "  inter_one.append(Beginning_Page + move_for_inter_one_2[i])\n",
        "  inter_two.append(Beginning_Page + (Interval_page + 1) + move_for_inter_two_2[i])\n",
        "\n",
        "print(inter_one,inter_two)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUEFOhiPiAbV",
        "outputId": "89ae7ef3-0380-42d1-d4e1-98ac7fa4a01e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26, 46, 66, 86, 106, 126] [47, 67, 87, 107, 127, 147]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ending_inter = [inter_one[-1],Number_page +1]\n",
        "Ending_inter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG3exwLqlWvM",
        "outputId": "d3fa5a95-547c-4628-dbae-9c51dcd7bfe1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[126, 127]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_tail = 'base_page_' + str(Ending_inter[0]) + '_to_' + str(Ending_inter[1]) + '.csv'"
      ],
      "metadata": {
        "id": "i5rp8ti6qF5f"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**End and debut of the database**"
      ],
      "metadata": {
        "id": "sOsiifondzG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take the example again, since you append every 20 page from page 26 to 134 and you used my code (part 1 or part 2) you must have several base named like this \n",
        "\n",
        "*   base_page_26_to_46\n",
        "*   base_page_46_to_66\n",
        "*   base_page_66_to_86\n",
        "*   ...\n",
        "*   base_page_106_to_126\n",
        "*   base_page_126_to_134\n",
        "\n",
        "As you can see the last one is not the same size as other, only 8 page to append, it's the tail of the dataframe so we treat it first"
      ],
      "metadata": {
        "id": "yBYdamSwfk-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (Ending_inter[1] - Ending_inter[0] != 1) == True:\n",
        "  base_tail_2 = pd.read_csv(io.BytesIO(uploaded[base_tail]))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "# If your ending tail is the end of the interval (like here if we just append page 26 to 126 every 20 page, the last base would have been base_page_106_to_126\n",
        "# therefore there's no need to add the end)"
      ],
      "metadata": {
        "id": "rOPUNuR7hoi_"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For the others base**"
      ],
      "metadata": {
        "id": "_ClV48boisqY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This part is just to generate every name base from begening (here page 26) to before ending (126) "
      ],
      "metadata": {
        "id": "G_Otb_VFixQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_base = []\n",
        "base_import = []\n",
        "for i in range(len(inter_one)-1):\n",
        "  name_base.append('base_page_' + str(inter_one[i]) + '_to_' + str(inter_two[i]) + '.csv')"
      ],
      "metadata": {
        "id": "9Om9AFmyjlI0"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUnMqhDNj1J2",
        "outputId": "ff643c3e-55ee-4132-8ab2-c37c7ff44596"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['base_page_26_to_47.csv',\n",
              " 'base_page_46_to_67.csv',\n",
              " 'base_page_66_to_87.csv',\n",
              " 'base_page_86_to_107.csv',\n",
              " 'base_page_106_to_127.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to upload every other file than the tail.\n",
        "With our example\n",
        "*   base_page_26_to_46\n",
        "*   base_page_46_to_66\n",
        "*   base_page_66_to_86\n",
        "*   base_page_86_to_106\n",
        "*   base_page_106_to_126"
      ],
      "metadata": {
        "id": "ojZVSi-Zi0ZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We read first every base you just uploaded"
      ],
      "metadata": {
        "id": "E3Q5Yi7Rrgj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base0 = []\n",
        "for i in range(len(name_base)):\n",
        "  base0.append(pd.read_csv(io.BytesIO(uploaded[name_base[i]])))"
      ],
      "metadata": {
        "id": "x5mvqKp-jXqW"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It create a list of database so we're adding the end tail "
      ],
      "metadata": {
        "id": "hko0V9dCrmoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (Ending_inter[1] - Ending_inter[0] != 1) == True:\n",
        "  base0.append(base_tail_2)\n",
        "\n",
        "# Note : The code is made as if your last file (the ending tail) is the same size as the other file you don't have to run this code"
      ],
      "metadata": {
        "id": "pK2c6Jl4klbf"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we create a unique database for every other database"
      ],
      "metadata": {
        "id": "4IMBHH-DuJPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bases = []\n",
        "for i in range(len(base0)):\n",
        "  bases.append(base0[i])\n",
        "  base1 = pd.concat(bases,ignore_index=True)\n",
        "len(base1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv1eQfh5rPRP",
        "outputId": "0af6203f-1a7f-4e36-c40e-f43756f4ae3c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2100"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you used my code, we have duplicate, let's fix it"
      ],
      "metadata": {
        "id": "Tf9B5wUOrvDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base1 = base1.drop_duplicates(subset=['ID'])\n",
        "len(base1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iMdqudar-rC",
        "outputId": "049aa146-6ef0-4966-c7a1-b863ffd4406b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2010"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "qEePIUw9sWlk",
        "outputId": "f1ab3c05-cb49-46cc-b404-40eb6b628288"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  Index_page        ID Date_publication  \\\n",
              "0              0          26  44500864      30 Jan 2023   \n",
              "1              1          26  44653189      31 Jan 2023   \n",
              "2              2          26  44653972      30 Jan 2023   \n",
              "3              3          26  42326040      30 Jan 2023   \n",
              "4              4          26  43707168      30 Jan 2023   \n",
              "...          ...         ...       ...              ...   \n",
              "2095         415         126  44351083      17 Jan 2023   \n",
              "2096         416         126  44352877      17 Jan 2023   \n",
              "2097         417         126  44343535      17 Jan 2023   \n",
              "2098         418         126  44343544      17 Jan 2023   \n",
              "2099         419         126  41070075      17 Jan 2023   \n",
              "\n",
              "                                       Title_and_author Language_of_the_work  \\\n",
              "0            and it’s a song you know by loveinhawkins               English   \n",
              "1             Sit With You In The Trenches by viharker               English   \n",
              "2                            Call My Bluff by viharker               English   \n",
              "3      I'm afraid I can't catch you (I'm falling too...              English   \n",
              "4                         sun down, you’re up by tkhwh               English   \n",
              "...                                                 ...                  ...   \n",
              "2095            Narnia Chatfic // Irlfic by shelbyshub               English   \n",
              "2096   Knight in Shining Armor by Are_you_ever_not_g...              English   \n",
              "2097   Rolled a 1 on the Check, Rolled a 20 on the S...              English   \n",
              "2098   Steve \"The Manager\" Harrington by Dragonkeppe...              English   \n",
              "2099        Well, My Boyfriend's In A Band by daynight               English   \n",
              "\n",
              "        Word Chapter   Hits  \\\n",
              "0      1,562     1/1    389   \n",
              "1      3,850     1/1    469   \n",
              "2      6,679     4/?    386   \n",
              "3     13,275     8/?    864   \n",
              "4      1,604     1/1   2372   \n",
              "...      ...     ...    ...   \n",
              "2095     425     2/?     60   \n",
              "2096   1,909     1/1    707   \n",
              "2097  91,802    25/?  21018   \n",
              "2098  24,180   20/20  17201   \n",
              "2099  38,333     6/?   4298   \n",
              "\n",
              "                                         Requiered_tags  \\\n",
              "0     | General Audiences| No Archive Warnings Apply...   \n",
              "1     | Explicit| No Archive Warnings Apply| F/M| Co...   \n",
              "2     | Mature| No Archive Warnings Apply| F/M| Work...   \n",
              "3     | General Audiences| Choose Not To Use Archive...   \n",
              "4     | Explicit| Choose Not To Use Archive Warnings...   \n",
              "...                                                 ...   \n",
              "2095  | Not Rated| Choose Not To Use Archive Warning...   \n",
              "2096  | Teen And Up Audiences| No Archive Warnings A...   \n",
              "2097  | Teen And Up Audiences| No Archive Warnings A...   \n",
              "2098  | Not Rated| No Archive Warnings Apply| M/M| C...   \n",
              "2099  | Explicit| No Archive Warnings Apply| Gen, M/...   \n",
              "\n",
              "                                       Additionnal_tags  \n",
              "0     |No Archive Warnings ApplyDustin Henderson & E...  \n",
              "1     |No Archive Warnings ApplyChrissy Cunningham/E...  \n",
              "2     |No Archive Warnings ApplyEden Bingham/Jason C...  \n",
              "3     |Creator Chose Not To Use Archive WarningsWill...  \n",
              "4     |Creator Chose Not To Use Archive WarningsStev...  \n",
              "...                                                 ...  \n",
              "2095  |Creator Chose Not To Use Archive WarningsSusa...  \n",
              "2096  |No Archive Warnings ApplyWill Byers/Mike Whee...  \n",
              "2097  |No Archive Warnings ApplySteve Harrington/Edd...  \n",
              "2098  |No Archive Warnings ApplySteve Harrington/Edd...  \n",
              "2099  |No Archive Warnings ApplySteve Harrington/Edd...  \n",
              "\n",
              "[2010 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35541516-f15d-428a-944c-38c6219f015b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Index_page</th>\n",
              "      <th>ID</th>\n",
              "      <th>Date_publication</th>\n",
              "      <th>Title_and_author</th>\n",
              "      <th>Language_of_the_work</th>\n",
              "      <th>Word</th>\n",
              "      <th>Chapter</th>\n",
              "      <th>Hits</th>\n",
              "      <th>Requiered_tags</th>\n",
              "      <th>Additionnal_tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>44500864</td>\n",
              "      <td>30 Jan 2023</td>\n",
              "      <td>and it’s a song you know by loveinhawkins</td>\n",
              "      <td>English</td>\n",
              "      <td>1,562</td>\n",
              "      <td>1/1</td>\n",
              "      <td>389</td>\n",
              "      <td>| General Audiences| No Archive Warnings Apply...</td>\n",
              "      <td>|No Archive Warnings ApplyDustin Henderson &amp; E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>44653189</td>\n",
              "      <td>31 Jan 2023</td>\n",
              "      <td>Sit With You In The Trenches by viharker</td>\n",
              "      <td>English</td>\n",
              "      <td>3,850</td>\n",
              "      <td>1/1</td>\n",
              "      <td>469</td>\n",
              "      <td>| Explicit| No Archive Warnings Apply| F/M| Co...</td>\n",
              "      <td>|No Archive Warnings ApplyChrissy Cunningham/E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>44653972</td>\n",
              "      <td>30 Jan 2023</td>\n",
              "      <td>Call My Bluff by viharker</td>\n",
              "      <td>English</td>\n",
              "      <td>6,679</td>\n",
              "      <td>4/?</td>\n",
              "      <td>386</td>\n",
              "      <td>| Mature| No Archive Warnings Apply| F/M| Work...</td>\n",
              "      <td>|No Archive Warnings ApplyEden Bingham/Jason C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "      <td>42326040</td>\n",
              "      <td>30 Jan 2023</td>\n",
              "      <td>I'm afraid I can't catch you (I'm falling too...</td>\n",
              "      <td>English</td>\n",
              "      <td>13,275</td>\n",
              "      <td>8/?</td>\n",
              "      <td>864</td>\n",
              "      <td>| General Audiences| Choose Not To Use Archive...</td>\n",
              "      <td>|Creator Chose Not To Use Archive WarningsWill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>43707168</td>\n",
              "      <td>30 Jan 2023</td>\n",
              "      <td>sun down, you’re up by tkhwh</td>\n",
              "      <td>English</td>\n",
              "      <td>1,604</td>\n",
              "      <td>1/1</td>\n",
              "      <td>2372</td>\n",
              "      <td>| Explicit| Choose Not To Use Archive Warnings...</td>\n",
              "      <td>|Creator Chose Not To Use Archive WarningsStev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2095</th>\n",
              "      <td>415</td>\n",
              "      <td>126</td>\n",
              "      <td>44351083</td>\n",
              "      <td>17 Jan 2023</td>\n",
              "      <td>Narnia Chatfic // Irlfic by shelbyshub</td>\n",
              "      <td>English</td>\n",
              "      <td>425</td>\n",
              "      <td>2/?</td>\n",
              "      <td>60</td>\n",
              "      <td>| Not Rated| Choose Not To Use Archive Warning...</td>\n",
              "      <td>|Creator Chose Not To Use Archive WarningsSusa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2096</th>\n",
              "      <td>416</td>\n",
              "      <td>126</td>\n",
              "      <td>44352877</td>\n",
              "      <td>17 Jan 2023</td>\n",
              "      <td>Knight in Shining Armor by Are_you_ever_not_g...</td>\n",
              "      <td>English</td>\n",
              "      <td>1,909</td>\n",
              "      <td>1/1</td>\n",
              "      <td>707</td>\n",
              "      <td>| Teen And Up Audiences| No Archive Warnings A...</td>\n",
              "      <td>|No Archive Warnings ApplyWill Byers/Mike Whee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2097</th>\n",
              "      <td>417</td>\n",
              "      <td>126</td>\n",
              "      <td>44343535</td>\n",
              "      <td>17 Jan 2023</td>\n",
              "      <td>Rolled a 1 on the Check, Rolled a 20 on the S...</td>\n",
              "      <td>English</td>\n",
              "      <td>91,802</td>\n",
              "      <td>25/?</td>\n",
              "      <td>21018</td>\n",
              "      <td>| Teen And Up Audiences| No Archive Warnings A...</td>\n",
              "      <td>|No Archive Warnings ApplySteve Harrington/Edd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2098</th>\n",
              "      <td>418</td>\n",
              "      <td>126</td>\n",
              "      <td>44343544</td>\n",
              "      <td>17 Jan 2023</td>\n",
              "      <td>Steve \"The Manager\" Harrington by Dragonkeppe...</td>\n",
              "      <td>English</td>\n",
              "      <td>24,180</td>\n",
              "      <td>20/20</td>\n",
              "      <td>17201</td>\n",
              "      <td>| Not Rated| No Archive Warnings Apply| M/M| C...</td>\n",
              "      <td>|No Archive Warnings ApplySteve Harrington/Edd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2099</th>\n",
              "      <td>419</td>\n",
              "      <td>126</td>\n",
              "      <td>41070075</td>\n",
              "      <td>17 Jan 2023</td>\n",
              "      <td>Well, My Boyfriend's In A Band by daynight</td>\n",
              "      <td>English</td>\n",
              "      <td>38,333</td>\n",
              "      <td>6/?</td>\n",
              "      <td>4298</td>\n",
              "      <td>| Explicit| No Archive Warnings Apply| Gen, M/...</td>\n",
              "      <td>|No Archive Warnings ApplySteve Harrington/Edd...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2010 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35541516-f15d-428a-944c-38c6219f015b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35541516-f15d-428a-944c-38c6219f015b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35541516-f15d-428a-944c-38c6219f015b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ]
}